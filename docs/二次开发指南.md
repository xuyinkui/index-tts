# IndexTTS 二次开发指南

## 快速开始

### 环境准备

1. **系统要求**
   - Python 3.10+
   - CUDA 11.8+ (推荐使用GPU)
   - 16GB+ RAM (推荐32GB)
   - 10GB+ 存储空间

2. **安装依赖**
```bash
# 创建虚拟环境
conda create -n index-tts python=3.10
conda activate index-tts

# 安装依赖
pip install -r requirements.txt

# Windows用户可能需要单独安装pynini
conda install -c conda-forge pynini==2.1.5
pip install WeTextProcessing==1.0.3
```

3. **下载模型**
```bash
# 使用huggingface-cli下载
huggingface-cli download IndexTeam/IndexTTS-1.5 \
  config.yaml bigvgan_discriminator.pth bigvgan_generator.pth \
  bpe.model dvae.pth gpt.pth unigram_12000.vocab \
  --local-dir checkpoints

# 或使用wget下载
mkdir -p checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/config.yaml -P checkpoints
# ... 其他文件
```

### 基础使用

#### 1. 命令行使用
```bash
# 安装为包
pip install -e .

# 命令行调用
indextts "你好，欢迎使用IndexTTS!" \
  --voice reference_voice.wav \
  --output output.wav \
  --model_dir checkpoints
```

#### 2. Python API使用
```python
from indextts.infer import IndexTTS

# 初始化TTS
tts = IndexTTS(
    cfg_path="checkpoints/config.yaml",
    model_dir="checkpoints",
    is_fp16=True,
    device="cuda:0"
)

# 生成语音
tts.infer(
    audio_prompt="reference.wav",
    text="要合成的文本内容",
    output_path="output.wav"
)
```

#### 3. Web界面
```bash
pip install -e ".[webui]"
python webui.py --port 7860
```

## 核心API详解

### IndexTTS 类

#### 初始化参数
```python
class IndexTTS:
    def __init__(
        self,
        cfg_path="checkpoints/config.yaml",  # 配置文件路径
        model_dir="checkpoints",             # 模型目录
        is_fp16=True,                       # 是否使用FP16
        device=None,                        # 设备选择
        use_cuda_kernel=None                # 是否使用CUDA内核
    ):
```

#### 核心方法

**1. infer() - 标准推理**
```python
def infer(
    self,
    audio_prompt,                    # 参考音频路径
    text,                           # 要合成的文本
    output_path,                    # 输出路径
    verbose=False,                  # 是否显示详细信息
    max_text_tokens_per_sentence=120, # 每句最大token数
    **generation_kwargs             # 生成参数
):
```

**2. infer_fast() - 批量推理**
```python
def infer_fast(
    self,
    audio_prompt,
    text,
    output_path,
    verbose=False,
    max_text_tokens_per_sentence=100,
    sentences_bucket_max_size=4,    # 批次大小
    **generation_kwargs
):
```

#### 生成参数说明
```python
generation_kwargs = {
    "do_sample": True,              # 是否采样
    "top_p": 0.8,                  # Top-p采样
    "top_k": 30,                   # Top-k采样
    "temperature": 1.0,            # 温度参数
    "length_penalty": 0.0,         # 长度惩罚
    "num_beams": 3,                # beam search数量
    "repetition_penalty": 10.0,    # 重复惩罚
    "max_mel_tokens": 600,         # 最大mel token数
}
```

## 二次开发场景

### 1. 批量音频生成

```python
import os
from indextts.infer import IndexTTS

class BatchTTS:
    def __init__(self, model_dir="checkpoints"):
        self.tts = IndexTTS(model_dir=model_dir)
    
    def batch_generate(self, tasks):
        """
        批量生成音频
        tasks: [{"audio_prompt": "ref.wav", "text": "文本", "output": "out.wav"}]
        """
        for i, task in enumerate(tasks):
            print(f"正在处理 {i+1}/{len(tasks)}: {task['text'][:20]}...")
            try:
                self.tts.infer(
                    audio_prompt=task["audio_prompt"],
                    text=task["text"],
                    output_path=task["output"]
                )
                print(f"✓ 完成: {task['output']}")
            except Exception as e:
                print(f"✗ 失败: {e}")

# 使用示例
batch_tts = BatchTTS()
tasks = [
    {
        "audio_prompt": "voice1.wav",
        "text": "第一段要合成的文本",
        "output": "output1.wav"
    },
    {
        "audio_prompt": "voice2.wav", 
        "text": "第二段要合成的文本",
        "output": "output2.wav"
    }
]
batch_tts.batch_generate(tasks)
```

### 2. 实时语音合成服务

```python
import asyncio
import threading
from queue import Queue
from indextts.infer import IndexTTS

class RealtimeTTS:
    def __init__(self, model_dir="checkpoints"):
        self.tts = IndexTTS(model_dir=model_dir)
        self.task_queue = Queue()
        self.is_running = False
        
    def start_service(self):
        """启动后台处理服务"""
        self.is_running = True
        worker_thread = threading.Thread(target=self._worker)
        worker_thread.start()
        
    def _worker(self):
        """后台处理任务"""
        while self.is_running:
            if not self.task_queue.empty():
                task = self.task_queue.get()
                try:
                    self.tts.infer(
                        audio_prompt=task["audio_prompt"],
                        text=task["text"],
                        output_path=task["output_path"]
                    )
                    if task.get("callback"):
                        task["callback"](True, task["output_path"])
                except Exception as e:
                    if task.get("callback"):
                        task["callback"](False, str(e))
            time.sleep(0.1)
                        
    def add_task(self, audio_prompt, text, output_path, callback=None):
        """添加合成任务"""
        task = {
            "audio_prompt": audio_prompt,
            "text": text,
            "output_path": output_path,
            "callback": callback
        }
        self.task_queue.put(task)
        
    def stop_service(self):
        """停止服务"""
        self.is_running = False

# 使用示例
def on_complete(success, result):
    if success:
        print(f"合成完成: {result}")
    else:
        print(f"合成失败: {result}")

realtime_tts = RealtimeTTS()
realtime_tts.start_service()
realtime_tts.add_task("ref.wav", "测试文本", "output.wav", on_complete)
```

### 3. 自定义文本预处理

```python
from indextts.utils.front import TextNormalizer, TextTokenizer

class CustomTextProcessor:
    def __init__(self, bpe_model_path):
        self.normalizer = TextNormalizer()
        self.normalizer.load()
        self.tokenizer = TextTokenizer(bpe_model_path, self.normalizer)
        
    def preprocess_text(self, text):
        """自定义文本预处理"""
        # 1. 清理文本
        text = self.clean_text(text)
        
        # 2. 处理特殊标记
        text = self.handle_special_tokens(text)
        
        # 3. 标准化
        normalized = self.normalizer.normalize(text)
        
        # 4. 分词
        tokens = self.tokenizer.tokenize(normalized)
        
        return tokens
        
    def clean_text(self, text):
        """文本清理"""
        import re
        # 移除多余空白
        text = re.sub(r'\s+', ' ', text)
        # 处理URL
        text = re.sub(r'http[s]?://[^\s]+', '[链接]', text)
        # 处理邮箱
        text = re.sub(r'\S+@\S+', '[邮箱]', text)
        return text.strip()
        
    def handle_special_tokens(self, text):
        """处理特殊标记"""
        # 添加停顿标记
        text = text.replace('...', '，')
        text = text.replace('——', '，')
        return text

# 集成到TTS中
class CustomTTS(IndexTTS):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.text_processor = CustomTextProcessor(self.bpe_path)
        
    def infer_with_custom_preprocessing(self, audio_prompt, text, output_path, **kwargs):
        """使用自定义预处理的推理"""
        # 使用自定义预处理
        processed_text = self.text_processor.preprocess_text(text)
        
        # 调用原始推理方法
        return super().infer(audio_prompt, processed_text, output_path, **kwargs)
```

### 4. 音频质量增强

```python
import librosa
import soundfile as sf
from scipy import signal

class AudioEnhancer:
    def __init__(self):
        pass
        
    def enhance_audio(self, input_path, output_path):
        """音频后处理增强"""
        # 加载音频
        audio, sr = librosa.load(input_path, sr=None)
        
        # 降噪
        audio = self.denoise(audio, sr)
        
        # 音量标准化
        audio = self.normalize_volume(audio)
        
        # 去除静音
        audio = self.trim_silence(audio, sr)
        
        # 保存
        sf.write(output_path, audio, sr)
        
    def denoise(self, audio, sr):
        """简单降噪"""
        # 使用滤波器去除低频噪声
        sos = signal.butter(5, 80, btype='high', fs=sr, output='sos')
        audio = signal.sosfilt(sos, audio)
        return audio
        
    def normalize_volume(self, audio):
        """音量标准化"""
        max_val = max(abs(audio.max()), abs(audio.min()))
        if max_val > 0:
            audio = audio / max_val * 0.8
        return audio
        
    def trim_silence(self, audio, sr, threshold=0.01):
        """去除首尾静音"""
        return librosa.effects.trim(audio, top_db=20)[0]

# 集成增强功能的TTS
class EnhancedTTS(IndexTTS):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.enhancer = AudioEnhancer()
        
    def infer_enhanced(self, audio_prompt, text, output_path, **kwargs):
        """带音频增强的推理"""
        temp_output = output_path.replace('.wav', '_temp.wav')
        
        # 生成原始音频
        super().infer(audio_prompt, text, temp_output, **kwargs)
        
        # 音频增强
        self.enhancer.enhance_audio(temp_output, output_path)
        
        # 清理临时文件
        os.remove(temp_output)
```

### 5. 多语言扩展

```python
class MultiLanguageTTS:
    def __init__(self, model_configs):
        """
        model_configs: {
            "zh": {"model_dir": "checkpoints_zh", "config": "config_zh.yaml"},
            "en": {"model_dir": "checkpoints_en", "config": "config_en.yaml"}
        }
        """
        self.models = {}
        for lang, config in model_configs.items():
            self.models[lang] = IndexTTS(
                cfg_path=config["config"],
                model_dir=config["model_dir"]
            )
    
    def detect_language(self, text):
        """简单的语言检测"""
        import re
        # 检测中文字符
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        
        if chinese_chars > english_chars:
            return "zh"
        else:
            return "en"
    
    def infer_multilingual(self, audio_prompt, text, output_path, language=None):
        """多语言推理"""
        if language is None:
            language = self.detect_language(text)
            
        if language not in self.models:
            raise ValueError(f"不支持的语言: {language}")
            
        return self.models[language].infer(audio_prompt, text, output_path)

# 使用示例
multi_tts = MultiLanguageTTS({
    "zh": {"model_dir": "checkpoints", "config": "checkpoints/config.yaml"},
    "en": {"model_dir": "checkpoints_en", "config": "checkpoints_en/config.yaml"}
})

multi_tts.infer_multilingual("ref.wav", "Hello world!", "output.wav")
```

## 性能优化建议

### 1. 内存优化

```python
class MemoryOptimizedTTS(IndexTTS):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
    def infer_memory_efficient(self, audio_prompt, text, output_path, **kwargs):
        """内存优化推理"""
        # 清理缓存
        if hasattr(torch.cuda, 'empty_cache'):
            torch.cuda.empty_cache()
            
        # 使用gradient checkpointing
        with torch.no_grad():
            result = super().infer(audio_prompt, text, output_path, **kwargs)
            
        # 再次清理缓存
        if hasattr(torch.cuda, 'empty_cache'):
            torch.cuda.empty_cache()
            
        return result
```

### 2. 并发处理

```python
import concurrent.futures
import threading

class ConcurrentTTS:
    def __init__(self, model_dir, num_workers=2):
        self.model_dir = model_dir
        self.num_workers = num_workers
        self.local = threading.local()
        
    def get_tts_instance(self):
        """获取线程本地的TTS实例"""
        if not hasattr(self.local, 'tts'):
            self.local.tts = IndexTTS(model_dir=self.model_dir)
        return self.local.tts
        
    def batch_process_concurrent(self, tasks):
        """并发批量处理"""
        def process_single(task):
            tts = self.get_tts_instance()
            return tts.infer(**task)
            
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            futures = [executor.submit(process_single, task) for task in tasks]
            results = []
            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    print(f"任务失败: {e}")
                    results.append(None)
        return results
```

### 3. 缓存优化

```python
import hashlib
import pickle
import os

class CachedTTS(IndexTTS):
    def __init__(self, cache_dir="cache", *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
    def _get_cache_key(self, audio_prompt, text, **kwargs):
        """生成缓存键"""
        # 读取音频文件的哈希
        with open(audio_prompt, 'rb') as f:
            audio_hash = hashlib.md5(f.read()).hexdigest()[:8]
        
        # 生成文本和参数的哈希
        text_params = f"{text}_{str(sorted(kwargs.items()))}"
        text_hash = hashlib.md5(text_params.encode()).hexdigest()[:8]
        
        return f"{audio_hash}_{text_hash}"
        
    def infer_cached(self, audio_prompt, text, output_path, **kwargs):
        """带缓存的推理"""
        cache_key = self._get_cache_key(audio_prompt, text, **kwargs)
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.wav")
        
        if os.path.exists(cache_path):
            # 使用缓存
            import shutil
            shutil.copy2(cache_path, output_path)
            print(f"使用缓存: {cache_key}")
            return output_path
        else:
            # 生成新音频
            result = super().infer(audio_prompt, text, output_path, **kwargs)
            # 保存到缓存
            import shutil
            shutil.copy2(output_path, cache_path)
            print(f"保存缓存: {cache_key}")
            return result
```

## 部署建议

### 1. Docker部署

```dockerfile
FROM pytorch/pytorch:2.1.2-cuda11.8-devel

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    && rm -rf /var/lib/apt/lists/*

# 复制代码
COPY . /app/

# 安装Python依赖
RUN pip install -r requirements.txt
RUN pip install -e .

# 下载模型(可选，也可以挂载)
# RUN huggingface-cli download IndexTeam/IndexTTS-1.5 --local-dir checkpoints

EXPOSE 7860

CMD ["python", "webui.py", "--host", "0.0.0.0", "--port", "7860"]
```

### 2. API服务

```python
from flask import Flask, request, send_file
import tempfile
import os

app = Flask(__name__)
tts = IndexTTS(model_dir="checkpoints")

@app.route('/synthesize', methods=['POST'])
def synthesize():
    # 获取参数
    text = request.form.get('text')
    audio_prompt = request.files.get('audio_prompt')
    
    if not text or not audio_prompt:
        return {"error": "缺少必要参数"}, 400
    
    try:
        # 保存临时文件
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_prompt:
            audio_prompt.save(temp_prompt.name)
            
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_output:
            # 生成语音
            tts.infer(temp_prompt.name, text, temp_output.name)
            
            # 返回音频文件
            return send_file(temp_output.name, mimetype='audio/wav')
            
    except Exception as e:
        return {"error": str(e)}, 500
    finally:
        # 清理临时文件
        if 'temp_prompt' in locals():
            os.unlink(temp_prompt.name)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## 常见问题与解决方案

### 1. 内存不足
- 使用CPU推理或较小的batch size
- 启用梯度检查点
- 定期清理GPU缓存

### 2. 生成质量问题
- 调整采样参数(temperature, top_p, top_k)
- 检查参考音频质量
- 调整文本分句长度

### 3. 速度优化
- 使用FP16推理
- 启用CUDA内核
- 使用批量推理模式

### 4. 模型加载失败
- 检查模型文件完整性
- 确认配置文件路径正确
- 检查CUDA版本兼容性

通过这份详细的二次开发指南，您可以基于IndexTTS构建各种定制化的语音合成应用。根据具体需求选择合适的扩展方案，并注意性能优化和错误处理。 