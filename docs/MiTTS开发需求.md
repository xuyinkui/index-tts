# Mi-TTS 二次开发需求

## 1. 项目结构调整

所有二次开发相关的代码，包括 API 接口、本地推理方法、缓存管理以及其他辅助功能，将统一放置在项目根目录下的 `mitts/` 目录中，以确保与原有 `indextts/` 模块的清晰分离，便于后期维护和扩展。

## 2. 角色和情绪功能

### 2.1 需求描述

本项目将扩展语音合成功能，支持基于预定义"角色"及其"情绪"进行语音合成。一个角色可以包含多种情绪，其中有一个情绪被设为默认情绪。
参考音频文件将统一存放在 `speakers/` 目录下。其详细结构如下：
`speakers/角色名称/情绪名称/参考音频文件.wav`

* 每个情绪目录下存放着对应的 `.wav` 格式参考音频文件，文件命名无特定约定，只要是系统正常名称即可。
* 当用户合成音频时，如果输入角色名称和情绪名称，系统将从对应的情绪目录下随机选择一个参考音频。
* 如果用户只输入角色名称，系统将从该角色的默认情绪目录下选择一个参考音频。**默认情绪的判断规则为：该角色目录下的第一个子目录。**
* 如果指定的情绪目录下没有音频文件，系统将报错。

### 2.2 参数配置优先级

为了实现不同情绪和角色的精细化参数定制，音频生成参数的配置将遵循以下优先级（从高到低）：

1. **主动传递的参数：** 用户在调用 API 或本地推理方法时直接传递的参数（例如 `conf` 参数中的键值，或本地方法中的 `**generation_kwargs`）。
2. **情绪目录下的 `tts_config.yaml`：** 如果选择的情绪目录下存在名为 `tts_config.yaml` 的文件，则优先使用其中的参数。
3. **角色目录下的 `tts_config.yaml`：** 如果情绪目录中没有 `tts_config.yaml`，则使用角色目录下（例如 `speakers/角色名称/tts_config.yaml`）的 `tts_config.yaml` 文件中的参数。
4. **系统配置参数：** 如果以上都没有指定，则使用系统默认的配置参数（通常来源于 `checkpoints/config.yaml` 或代码中的默认值）。

### 2.3 管理方式

前期，角色和情绪的管理将通过手动创建和维护 `speakers/` 目录下的文件夹结构来实现，降低初期复杂度。

### 2.4 异常处理

如果用户输入了不存在的"角色名称"或"情绪名称"，系统将返回明确的错误信息。



## 3. API 接口设计

### 3.1 API 框架

使用 FastAPI 构建 RESTful API 接口。

### 3.2 `/tts` 端点

* **HTTP 方法：** `POST`

* **请求体 (Request Body) 参数：**
  * `text` (字符串，必填)：需要合成的文本内容。
  * `audio_prompt` (多种类型，可选)：参考音频。优先级如下：
        1. **文件上传 (File Upload)：** 直接上传的 `.wav` 格式音频文件。此方式优先级最高。在 API 层面，这将通过 `fastapi.UploadFile` 类型进行接收。
        2. **本地路径 (Local Path)：** 服务器上参考音频文件的本地路径。仅在未提供文件上传时有效。在 API 层面，这将作为字符串 (`str`) 类型接收。
        3. **MD5 值 (MD5 Hash)：** 已上传并缓存的参考音频文件的 MD5 校验和。仅在未提供文件上传和本地路径时有效。在 API 层面，这也将作为字符串 (`str`) 类型接收。
        *如果以上任一方式提供了有效音频，系统会首先检查其是否为文件上传，然后检查是否为有效文件路径，最后才检查是否为已缓存的 MD5 值。`speaker` 和 `emo` 参数将被忽略。如果未提供任何 `audio_prompt` 方式，系统将回退到基于 `speaker` 和 `emo` 的方式。*
  * `speaker` (字符串，可选)：指定合成语音的角色名称。仅在未提供 `audio_prompt` 时有效。
  * `emo` (字符串，可选)：指定角色的情绪名称。仅在未提供 `audio_prompt` 且提供了 `speaker` 时有效。如果未提供，系统将使用该角色的默认情绪。
  * `conf` (JSON 对象，可选)：用于在运行时动态覆盖 `tts_config.yaml` 中的参数，其优先级最高。该参数可包含以下音频生成参数：
    * `do_sample` (布尔值): 是否启用采样。 (默认: `True`)
    * `top_p` (浮点数): Top-p (nucleus) 采样阈值，范围 `[0.0, 1.0]`。 (默认: `0.8`)
    * `top_k` (整数): Top-k 采样候选数量，范围 `[1, 100]`。 (默认: `30`)
    * `temperature` (浮点数): 采样温度，范围 `[0.1, 2.0]`。 (默认: `1.0`)
    * `length_penalty` (浮点数): 长度惩罚，范围 `[-2.0, 2.0]`。 (默认: `0.0`)
    * `num_beams` (整数): Beam search 束宽，范围 `[1, 10]`。 (默认: `3`)
    * `repetition_penalty` (浮点数): 重复惩罚，范围 `[0.1, 20.0]`。 (默认: `10.0`)
    * `max_mel_tokens` (整数): 最大生成 mel token 数，范围 `[50, 2000]`。 (默认: `600`)
    * `max_text_tokens_per_sentence` (整数): 每句最大 token 数，用于文本分句。(默认: `120`)
    * `sentences_bucket_max_size` (整数): 分句分桶的最大容量，仅在批量推理模式下有效。(默认: `4`)
  * `output_format` (字符串，可选)：指定合成音频的输出文件格式（例如 `mp3`, `ogg`, `flac`）。
  * `speed` (浮点数，可选)：调整生成音频的播放速度（例如 `1.0` 为原速，`0.5` 为半速，`2.0` 为双倍速）。

* **响应 (Response) 格式：**
  * **成功响应：** 返回合成音频的二进制流 (Content-Type: `audio/wav`)。
  * **错误响应：** 返回包含明确错误信息（例如，`400 Bad Request`，错误信息为 JSON 对象，如 `{"error": "角色或情绪不存在"}`）的 JSON 对象。

### 3.3 获取角色和情绪列表端点

* **端点 (Endpoint)：** 建议使用 `/speakers`
* **HTTP 方法：** `GET`
* **请求参数：** 无
* **响应 (Response) 格式：** 返回一个 JSON 对象，包含所有可用的角色及其对应的情绪列表。例如：

    ```json
    {
        "speakers": [
            {
                "name": "角色A",
                "emotions": ["开心", "悲伤", "默认情绪"]
            },
            {
                "name": "角色B",
                "emotions": ["愤怒", "平静"]
            }
        ]
    }
    ```

## 4. 本地推理方法

### 4.1 需求描述

需要提供一个独立的 Python 方法或类，用于在不启动 FastAPI 服务的情况下，通过"角色和情绪"方式（或直接参考音频方式）进行本地音频合成。此方法将放置在 `mitts/` 目录中。

### 4.2 参数

该方法将接收与 `IndexTTS.infer()` 类似的参数，包括：

* `text` (字符串，必填)：需要合成的文本内容。
* `audio_prompt` (字符串，可选)：直接提供的参考音频文件路径。如果提供此参数，将优先使用此参考音频，忽略 `speaker` 和 `emo` 参数。
* `speaker` (字符串，可选)：指定合成语音的角色名称。仅在未提供 `audio_prompt` 时有效。
* `emo` (字符串，可选)：指定角色的情绪名称。仅在未提供 `audio_prompt` 且提供了 `speaker` 时有效。如果未提供，系统将使用该角色的默认情绪。
* `output_path` (字符串，必填)：输出音频文件的保存路径。
* `output_format` (字符串，可选)：指定合成音频的输出文件格式（例如 `mp3`, `ogg`, `flac`）。
* `speed` (浮点数，可选)：调整生成音频的播放速度（例如 `1.0` 为原速，`0.5` 为半速，`2.0` 为双倍速）。
* `**generation_kwargs`：所有音频生成参数作为独立的关键字参数，与 `IndexTTS.infer()` 的 `**generation_kwargs` 保持一致（例如 `do_sample`, `top_p` 等）。

### 4.3 返回值

该方法将直接返回合成音频的路径。

## 5. 参考音频缓存管理

### 5.1 需求描述

为了提高效率和避免重复上传，将对上传的参考音频进行缓存。

### 5.2 缓存配置

* **缓存目录：** 允许用户通过配置指定参考音频缓存文件的存放目录（例如，默认路径为 `cache/`）。
* **缓存有效期：** 允许用户设置缓存文件的有效期（例如，N 天后过期），在此期限后文件将被视为过期。

### 5.3 定期清理机制

需要提供一个机制来定期（例如，每天或每周，可配置）清理过期或不再使用的缓存文件，以释放磁盘空间。清理时应删除超过有效期的文件。
* **选定方案：** 基于时间间隔的自动清理。将在 Mi-TTS 的 FastAPI 服务运行过程中，通过集成定时任务的方式，定期清理过期缓存文件。

## 6. 音频处理功能扩展

本项目将利用 `ffmpeg-python` 库的能力，在语音合成后对音频进行后处理。

### 6.1 支持生成不同格式的音频文件

* **需求描述：** 允许用户指定合成音频的输出文件格式，例如 `.mp3`, `.ogg`, `.flac` 等。
* **实现方式：** 在完成 `.wav` 格式的语音合成后，利用 `ffmpeg-python` 将其转换为目标格式。
* **参数集成：** 在 API 接口 (`/tts`) 和本地推理方法中增加一个可选参数 `output_format` (字符串)，用于指定输出格式（例如 `mp3`, `ogg`）。

### 6.2 变速功能

* **需求描述：** 允许用户调整生成音频的播放速度，例如 `0.5x` (慢速) 到 `2.0x` (快速)。
* **实现方式：** 在完成语音合成后，利用 `ffmpeg-python` 对音频进行变速处理。
* **参数集成：** 在 API 接口 (`/tts`) 和本地推理方法中增加一个可选参数 `speed` (浮点数)，用于指定变速比例 (例如 `1.0` 为原速)。
